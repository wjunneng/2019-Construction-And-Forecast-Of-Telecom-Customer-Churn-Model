{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "project_path = '/home/wjunneng/Python/2019-Construction-And-Forecast-Of-Telecom-Customer-Churn-Model'\n",
    "\n",
    "train_15p_cache_path = project_path + '/data/cache/train_15p.h5'\n",
    "train_85p_cache_path = project_path + '/data/cache/train_85p.h5'\n",
    "\n",
    "train_15p = pd.read_hdf(path_or_buf=train_15p_cache_path, mode='r', key='train_15p')\n",
    "train_85p = pd.read_hdf(path_or_buf=train_85p_cache_path, mode='r', key='train_85p')\n",
    "\n",
    "# 剔除Churn属性\n",
    "columns = list(train_15p.columns)\n",
    "columns.remove('Churn')\n",
    "\n",
    "X_test = train_85p\n",
    "X_train = train_15p[columns]\n",
    "y_train = train_15p['Churn'].astype(int)\n",
    "\n",
    "X_test = X_test.fillna(0)\n",
    "X_train = X_train.fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "KNeighborsClassifier      CV-5 R2:  -0.34 (+/- 0.35)\n",
      "SVC                       CV-5 R2:  -0.17 (+/- 0.01)\n",
      "SVC                       CV-5 R2:  -0.17 (+/- 0.01)\n",
      "GaussianProcessClassifier CV-5 R2:  -0.17 (+/- 0.01)\nDecisionTreeClassifier    CV-5 R2:  -0.95 (+/- 1.84)\nRandomForestClassifier    CV-5 R2:  -0.19 (+/- 0.04)\n",
      "MLPClassifier             CV-5 R2:  -1.64 (+/- 1.53)\nAdaBoostClassifier        CV-5 R2:  -0.38 (+/- 0.37)\nGaussianNB                CV-5 R2:  -0.71 (+/- 0.86)\nQuadraticDiscriminantAnalysis CV-5 R2:  -0.46 (+/- 0.45)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model_factory = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis()\n",
    "]\n",
    "\n",
    "for model in model_factory:\n",
    "    model.seed = 42\n",
    "    num_folds = 3\n",
    "\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=num_folds, scoring='r2', n_jobs=8)\n",
    "    score_description = \" %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2)\n",
    "\n",
    "    print('{model:25} CV-5 R2: {score}'.format(\n",
    "        model=model.__class__.__name__,\n",
    "        score=score_description\n",
    "    ))\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "\n",
    "class PseudoLabeler(BaseEstimator, RegressorMixin):\n",
    "    \"\"\"\n",
    "    Sci-kit learn wrapper for creating pseudo-lebeled estimators.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, unlabled_data, features, target, sample_rate=0.2, seed=42):\n",
    "        \"\"\"\n",
    "        @sample_rate - percent of samples used as pseudo-labelled data\n",
    "                       from the unlabled dataset\n",
    "        \"\"\"\n",
    "        assert sample_rate <= 1.0, 'Sample_rate should be between 0.0 and 1.0.'\n",
    "        \n",
    "        self.sample_rate = sample_rate\n",
    "        self.seed = seed\n",
    "        self.model = model\n",
    "        self.model.seed = seed\n",
    "        \n",
    "        self.unlabled_data = unlabled_data\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        \n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            \"sample_rate\": self.sample_rate,\n",
    "            \"seed\": self.seed,\n",
    "            \"model\": self.model,\n",
    "            \"unlabled_data\": self.unlabled_data,\n",
    "            \"features\": self.features,\n",
    "            \"target\": self.target\n",
    "        }\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fit the data using pseudo labeling.\n",
    "        \"\"\"\n",
    "\n",
    "        augemented_train = self.__create_augmented_train(X, y)\n",
    "        self.model.fit(\n",
    "            augemented_train[self.features],\n",
    "            augemented_train[self.target]\n",
    "        )\n",
    "        \n",
    "        return self\n",
    "\n",
    "\n",
    "    def __create_augmented_train(self, X, y):\n",
    "        \"\"\"\n",
    "        Create and return the augmented_train set that consists\n",
    "        of pseudo-labeled and labeled data.\n",
    "        \"\"\"        \n",
    "        num_of_samples = int(len(self.unlabled_data) * self.sample_rate)\n",
    "        \n",
    "        # Train the model and creat the pseudo-labels\n",
    "        self.model.fit(X, y)\n",
    "        pseudo_labels = self.model.predict(self.unlabled_data[self.features])\n",
    "        \n",
    "        # Add the pseudo-labels to the test set\n",
    "        pseudo_data = self.unlabled_data.copy(deep=True)\n",
    "        pseudo_data[self.target] = pseudo_labels\n",
    "        \n",
    "        # Take a subset of the test set with pseudo-labels and append in onto\n",
    "        # the training set\n",
    "        sampled_pseudo_data = pseudo_data.sample(n=num_of_samples)\n",
    "        temp_train = pd.concat([X, y], axis=1)\n",
    "        augemented_train = pd.concat([sampled_pseudo_data, temp_train])\n",
    "\n",
    "        return shuffle(augemented_train)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Returns the predicted values.\n",
    "        \"\"\"\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def get_model_name(self):\n",
    "        return self.model.__class__.__name__\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = PseudoLabeler(\n",
    "    XGBClassifier(nthread=10),\n",
    "    X_test,\n",
    "    X_test.columns,\n",
    "    'Churn'\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "predict = model.predict(train_85p)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "XGBClassifier             CV-8 R2: 0.8719 (+/- 0.1045)\n",
      "PseudoLabeler             CV-8 R2: 0.8733 (+/- 0.1041)\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "/home/wjunneng/Python/anaconda3/envs/lightgbm/lib/python3.6/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n  \"timeout or by a memory leak.\", UserWarning\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "model_factory = [\n",
    "    XGBClassifier(nthread=10),\n",
    "    \n",
    "    PseudoLabeler(\n",
    "        XGBClassifier(nthread=10),\n",
    "        X_test,\n",
    "        X_test.columns,\n",
    "        'Churn',\n",
    "        sample_rate=0.3\n",
    "    ),\n",
    "]\n",
    "\n",
    "for model in model_factory:\n",
    "    model.seed = 42\n",
    "    num_folds = 8\n",
    "    \n",
    "    scores = cross_val_score(model, X_train, y_train, cv=num_folds, scoring='accuracy', n_jobs=8)\n",
    "    score_description = \"R2: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2)\n",
    "\n",
    "    print('{model:25} CV-{num_folds} {score_cv}'.format(\n",
    "        model=model.__class__.__name__,\n",
    "        num_folds=num_folds,\n",
    "        score_cv=score_description\n",
    "    ))\n",
    "    \n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "KNeighborsClassifier\n"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-d58210776837>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Calculate the CV-3 R2 score and store it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-d58210776837>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Calculate the CV-3 R2 score and store it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/pycharm-professional-2019.1.3/pycharm-2019.1.3/helpers/pydev/_pydevd_bundle/pydevd_frame.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0;31m# if thread has a suspend flag, we suspend with a busy wait\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpydev_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mSTATE_SUSPEND\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_wait_suspend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/pycharm-professional-2019.1.3/pycharm-2019.1.3/helpers/pydev/_pydevd_bundle/pydevd_frame.py\u001b[0m in \u001b[0;36mdo_wait_suspend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_wait_suspend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_wait_suspend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;31m# IFDEF CYTHON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Python/pycharm-professional-2019.1.3/pycharm-2019.1.3/helpers/pydev/pydevd.py\u001b[0m in \u001b[0;36mdo_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, send_suspend_message)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_internal_commands\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel_async_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_thread_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "sns.set(color_codes=True)\n",
    "sample_rates = np.linspace(0, 1, 10)\n",
    "\n",
    "def pseudo_label_wrapper(model):\n",
    "    return PseudoLabeler(model, train_85p, train_85p.columns, 'Churn')\n",
    "\n",
    "# List of all models to test\n",
    "model_factory = [\n",
    "    KNeighborsClassifier(3),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0), warm_start=True),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    XGBClassifier(),\n",
    "    LGBMClassifier()\n",
    "]\n",
    "\n",
    "# Apply the PseudoLabeler class to each model\n",
    "model_factory = map(pseudo_label_wrapper, model_factory)\n",
    "\n",
    "# Train each model with different sample rates\n",
    "results = {}\n",
    "num_folds = 5\n",
    "\n",
    "for model in model_factory:\n",
    "    model_name = model.get_model_name()\n",
    "    print('%s' % model_name)\n",
    "\n",
    "    results[model_name] = list()\n",
    "    for sample_rate in sample_rates:\n",
    "        model.sample_rate = sample_rate\n",
    "        \n",
    "        # Calculate the CV-3 R2 score and store it\n",
    "        scores = cross_val_score(model, X_train, y_train, cv=num_folds, scoring='accuracy', n_jobs=11)\n",
    "        results[model_name].append(scores.mean())\n",
    "\n",
    "print(results)\n",
    "    \n",
    "plt.figure(figsize=(18, 18))\n",
    "\n",
    "i = 1\n",
    "for model_name, performance in results.items():    \n",
    "    plt.subplot(4, 3, i)\n",
    "    i += 1\n",
    "    \n",
    "    plt.plot(sample_rates, performance)\n",
    "    plt.title(model_name)\n",
    "    plt.xlabel('sample_rate')\n",
    "    plt.ylabel('Accuracy-score')\n",
    "    \n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "pycharm-e50da876",
   "language": "python",
   "display_name": "PyCharm (ForecastScore)"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}